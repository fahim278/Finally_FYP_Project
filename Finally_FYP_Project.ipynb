{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3-w2pj_NDUx",
        "outputId": "25deb47b-a543-4b45-faf4-b2251352c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "SK6tA_HqNlpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "# Paths\n",
        "BASE_DIR = \"/content/drive/MyDrive/dataset/training_set\"\n",
        "AUG_SUFFIX = \"_aug\"\n",
        "\n",
        "# Define transformations\n",
        "augmentations = T.Compose([\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(10),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    T.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    T.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "])\n",
        "\n",
        "# Augment each class folder\n",
        "for label_folder in os.listdir(BASE_DIR):\n",
        "    class_path = os.path.join(BASE_DIR, label_folder)\n",
        "    if not os.path.isdir(class_path): continue\n",
        "\n",
        "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    for idx, image_name in enumerate(images):\n",
        "        img_path = os.path.join(class_path, image_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        for aug_idx in range(3):  # 3 augmented copies per image\n",
        "            aug_img = augmentations(img)\n",
        "            new_name = f\"{os.path.splitext(image_name)[0]}{AUG_SUFFIX}_{aug_idx}.jpg\"\n",
        "            aug_img.save(os.path.join(class_path, new_name))\n",
        "\n",
        "print(\"âœ… Dataset Augmentation Completed.\")\n",
        "print(f\"âœ… Augmented: {new_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-rPfkCHQ392",
        "outputId": "1269eb96-61e6-4345-89d7-4c93b80c9f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset Augmentation Completed.\n",
            "âœ… Augmented: IMG_20200215_173815_aug_2_aug_2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Configs\n",
        "data_dir = \"/content/drive/MyDrive/dataset\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "traits = ['Agreeableness', 'Conscientiousness', 'Extraversion', 'Neuroticism', 'Openness']\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Dataset & Loader\n",
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"training_set\"), transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test_set\"), transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Save class index mapping\n",
        "import json\n",
        "with open(\"class_map.json\", \"w\") as f:\n",
        "    json.dump(train_dataset.class_to_idx, f)\n",
        "\n",
        "# Model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(traits))\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        total += images.size(0)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / total:.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images).argmax(1).cpu()\n",
        "        y_true += labels.tolist()\n",
        "        y_pred += outputs.tolist()\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=traits))\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"personality_resnet50_augmented.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WFb8yAfRRuq",
        "outputId": "30e823af-fefd-495c-a2c4-be2bd4c55c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 187MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.3826\n",
            "Epoch 2, Loss: 0.8663\n",
            "Epoch 3, Loss: 0.5677\n",
            "Epoch 4, Loss: 0.3287\n",
            "Epoch 5, Loss: 0.1713\n",
            "Epoch 6, Loss: 0.0995\n",
            "Epoch 7, Loss: 0.0656\n",
            "Epoch 8, Loss: 0.0786\n",
            "Epoch 9, Loss: 0.0725\n",
            "Epoch 10, Loss: 0.0389\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "    Agreeableness       1.00      0.75      0.86         8\n",
            "Conscientiousness       0.23      0.38      0.29         8\n",
            "     Extraversion       1.00      1.00      1.00         2\n",
            "      Neuroticism       0.27      0.38      0.32         8\n",
            "         Openness       0.58      0.39      0.47        18\n",
            "\n",
            "         accuracy                           0.48        44\n",
            "        macro avg       0.62      0.58      0.59        44\n",
            "     weighted avg       0.56      0.48      0.50        44\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from openai import OpenAI\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "MODEL_PATH = \"personality_resnet50_augmented.pth\"  # Your trained model\n",
        "CLASS_NAMES = ['Agreeableness', 'Conscientiousness', 'Extraversion', 'Neuroticism', 'Openness']\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/dataset/test_set/Openness/IMG_20200215_182135.jpg\"# Your test image path\n",
        "#OPENAI_API_KEY = \"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\"  # âœ… Your real API key here\n",
        "# ============================\n",
        "\n",
        "# âœ… Load ResNet Model\n",
        "def load_model():\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
        "    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# âœ… Predict trait from image\n",
        "def predict_image(image_path, model):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to load image: {e}\")\n",
        "        return None\n",
        "\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "    return CLASS_NAMES[pred.item()]\n",
        "\n",
        "# âœ… Ask LLM for advice\n",
        "def ask_llm_for_advice(trait):\n",
        "    try:\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful personality advisor.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"My personality trait is {trait}. Please give me practical and kind life advice based on it.\"}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ LLM Error: {e}\"\n",
        "\n",
        "# âœ… MAIN\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸ”„ Loading model...\")\n",
        "    model = load_model()\n",
        "\n",
        "    print(\"ðŸ” Predicting personality trait...\")\n",
        "    trait = predict_image(IMAGE_PATH, model)\n",
        "    if trait:\n",
        "        print(f\"ðŸ§  Predicted Trait: {trait}\")\n",
        "        print(\"ðŸ§  Asking LLM for advice...\")\n",
        "        advice = ask_llm_for_advice(trait)\n",
        "        print(f\"ðŸ’¡ Personalized Advice:\\n{advice}\")\n",
        "    else:\n",
        "        print(\"âŒ Prediction failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRqFimnUSI8t",
        "outputId": "ab5d48e9-7909-4e4f-aea1-87454a867da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Loading model...\n",
            "ðŸ” Predicting personality trait...\n",
            "ðŸ§  Predicted Trait: Conscientiousness\n",
            "ðŸ§  Asking LLM for advice...\n",
            "ðŸ’¡ Personalized Advice:\n",
            "âŒ LLM Error: name 'OPENAI_API_KEY' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/dataset\"\n",
        "\n",
        "# Training set\n",
        "train_path = os.path.join(data_dir, \"training_set\")\n",
        "print(\"Training images count:\")\n",
        "for cls in os.listdir(train_path):\n",
        "    cls_path = os.path.join(train_path, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        print(cls, \":\", len(os.listdir(cls_path)))\n",
        "\n",
        "# Test set\n",
        "test_path = os.path.join(data_dir, \"test_set\")\n",
        "print(\"\\nTest images count:\")\n",
        "for cls in os.listdir(test_path):\n",
        "    cls_path = os.path.join(test_path, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        print(cls, \":\", len(os.listdir(cls_path)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrGk2wzPb01n",
        "outputId": "f4f2200e-ef9d-43e4-bab7-efbd33bd98fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images count:\n"
          ]
        }
      ]
    }
  ]
}